{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentinel_Lakes_Delineation_DeepLearning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sghuffar/Glacial_Lakes_Sentinel/blob/master/Sentinel_Lakes_Delineation_DeepLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzqG3bhaLGU7",
        "colab_type": "text"
      },
      "source": [
        "This is a code to segment a Sentinel-2 image in to water and non water binary image. The segmentation is performed using the U-Net convolutional Neural Network model trained using the Pytorch Library. \n",
        "Part of the code is based on the following implementation: Deep networks for Earth Observation (https://github.com/nshaud/DeepNetsForEO). I would like to hereby acknowledge that the above mentioned respository has helped me in getting starting with Deep Learning for remote sensing image segmentation using Pytorch. I am grateful to the authors for sharing their code. \n",
        "\n",
        "In order to run this code, a Google account is required. The Sentinel-2 image is exported from the EarthEngine to the Drive and then feeded in to the neural network for prediction. The exporting of the image to the Google Drive may take 10-20 minutes. Large size may crash colab\n",
        "\n",
        "The False color original image as well as the predicted mask is then displayed on the map. \n",
        "\n",
        "The user needs to auhtorize access to the Google Drive below\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7r6sheJmYdl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "3a3b3f00-14d5-4cc4-e001-7c61ccf55c89"
      },
      "source": [
        "!pip install pyproj   # pyproj is required for coordinate transformations\n",
        "!pip install rasterio \n",
        "import rasterio as rio\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "import torch.nn.functional as F\n",
        "from skimage import io\n",
        "from glob import glob\n",
        "import folium   # for visualizing maps and images\n",
        "import random\n",
        "import itertools\n",
        "import gdal\n",
        "import matplotlib.pyplot as plt\n",
        "import os.path\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import os\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms  \n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler\n",
        "import torch.nn.init\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from pyproj import Proj, transform\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')\n",
        "    \n",
        "use_cuda = True\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyproj in /usr/local/lib/python3.6/dist-packages (2.6.1.post1)\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.6/dist-packages (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from rasterio) (1.18.5)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from rasterio) (19.3.0)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.6/dist-packages (from rasterio) (2.3.0)\n",
            "Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.6/dist-packages (from rasterio) (7.1.2)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.6/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: snuggs>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from rasterio) (1.4.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.6/dist-packages (from rasterio) (0.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.6/dist-packages (from snuggs>=1.4.1->rasterio) (2.4.7)\n",
            "1.5.1+cu101\n",
            "CUDA is available!  Training on GPU ...\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5pRKw-wawGA",
        "colab_type": "text"
      },
      "source": [
        "As we are using Earth Engine libraries to read and export the Landsat image, one would need to authorize access for Earth Engine. Copy paste the code below for authorization. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O75RRJRqmk-M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "outputId": "e9cd9209-fe34-4f8d-b5c8-ef4f303b17bb"
      },
      "source": [
        "!pip install earthengine-api  # install the Earth Engine API\n",
        "!earthengine authenticate\n",
        "import ee\n",
        "ee.Initialize()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: earthengine-api in /usr/local/lib/python3.6/dist-packages (0.1.227)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from earthengine-api) (1.17.2)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from earthengine-api) (0.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from earthengine-api) (1.12.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from earthengine-api) (0.17.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from earthengine-api) (0.16.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.6/dist-packages (from earthengine-api) (1.7.12)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.6/dist-packages (from earthengine-api) (1.18.1)\n",
            "Requirement already satisfied: httplib2shim in /usr/local/lib/python3.6/dist-packages (from earthengine-api) (0.0.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->earthengine-api) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->earthengine-api) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->earthengine-api) (4.6)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->earthengine-api) (49.1.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client->earthengine-api) (3.0.1)\n",
            "Requirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage->earthengine-api) (0.4.1)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage->earthengine-api) (1.0.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from httplib2shim->earthengine-api) (2020.6.20)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from httplib2shim->earthengine-api) (1.24.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->earthengine-api) (0.4.8)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->earthengine-api) (1.16.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->earthengine-api) (2018.9)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->earthengine-api) (3.12.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->earthengine-api) (2.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->earthengine-api) (1.52.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->earthengine-api) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->earthengine-api) (3.0.4)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "Running command using Cloud API.  Set --no-use_cloud_api to go back to using the API\n",
            "\n",
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&code_challenge=zfHeZVl7wFPjj7raoNYCMV77P1Ynabt2ayLV-G4JH_U&code_challenge_method=S256\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below. \n",
            "Enter verification code: 4/2QGNnDpmFPagDu1bhUp2z7bOMGZn6W17EM5ZsjGdJkweK8CRWwK4w4Q\n",
            "\n",
            "Successfully saved authorization token.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgTa635xi2Vk",
        "colab_type": "text"
      },
      "source": [
        "Below we select a Sentinel-2 image. At the moment only a central region of the image is exported because exporting a full image takes quite long time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1niJ1mguhZ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "outputId": "734ce123-5553-4977-86c9-508a45935904"
      },
      "source": [
        "image=ee.Image('COPERNICUS/S2/20180806T053641_20180806T054709_T43SFV')  #change the name of this image if testing on another image is required\n",
        "projI=image.select('B2').projection().getInfo()    # Exporting the whole image takes time, therefore, roughly select the center region of the image\n",
        "metadata=image.select('B2').getInfo()\n",
        "print(metadata)\n",
        "dim=metadata.get('bands')[0]\n",
        "print(dim)\n",
        "dim=dim.get('dimensions')\n",
        "print(dim)\n",
        "\n",
        "crs=projI['crs']\n",
        "outProj=Proj(init='epsg:4326')\n",
        "inProj=Proj(init=crs)\n",
        "kk=projI['transform']\n",
        "print(projI)\n",
        "print(kk)\n",
        "lon1, lat1=transform(inProj,outProj,kk[2],kk[5])\n",
        "lon2, lat2=transform(inProj,outProj,kk[2]+dim[0]*10,kk[5]-dim[1]*10) \n",
        "\n",
        "bounds = [lon1, lat2, lon2, lat1]\n",
        "print(bounds,lon1,lat1)\n",
        "\n",
        "imageL7=image.select(['B1','B2','B3','B4','B5','B6','B7','B8','B8A','B9','B10','B11','B12'])\n",
        "#imageL7=image.select(['B2'])\n",
        "\n",
        "geometry = ([lon1, lat1],[lon1,lat2],[lon2,lat2],[lon2 ,lat1])\n",
        "print(geometry)\n",
        "config= {\n",
        "    'description':'20180806T053641_20180806T054709_T43SFV',    \n",
        "    'region':geometry ,\n",
        "    'scale': 10,  #the image is exported with 15m resolution\n",
        "    'fileFormat': 'GeoTIFF',\n",
        "    'maxPixels':'10000000000000'\n",
        "}\n",
        "exp=ee.batch.Export.image.toDrive(imageL7,**config);\n",
        "\n",
        "exp.start()   # It takes around 5-10 minutes for 6000 * 6000 * 8 image to be exported \n",
        "print(exp.status())\n",
        "print(ee.batch.Task.list())\n",
        "import time\n",
        "while exp.active():\n",
        "  print('Transferring Data to Drive..................')\n",
        "  time.sleep(30)\n",
        "print('Done with the Export to the Drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'type': 'Image', 'bands': [{'id': 'B2', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': 0, 'max': 65535}, 'dimensions': [10980, 10980], 'crs': 'EPSG:32643', 'crs_transform': [10, 0, 600000, 0, -10, 4000020]}], 'id': 'COPERNICUS/S2/20180806T053641_20180806T054709_T43SFV', 'version': 1534627439370661, 'properties': {'DATATAKE_IDENTIFIER': 'GS2A_20180806T053641_016304_N02.06', 'SPACECRAFT_NAME': 'Sentinel-2A', 'MEAN_INCIDENCE_AZIMUTH_ANGLE_B8A': 217.650662986, 'MEAN_SOLAR_AZIMUTH_ANGLE': 136.06640453, 'system:footprint': {'type': 'LinearRing', 'coordinates': [[76.11137015041298, 36.13975304210107], [76.11136917703857, 36.13974179058083], [76.10447468069863, 35.644940487022964], [76.0977462120155, 35.150097321980795], [76.09779037220943, 35.15005548173873], [76.09782780659111, 35.15000940176183], [76.09784586004814, 35.1500064857658], [77.30244104651541, 35.13310073708927], [77.30249276394431, 35.13313636023269], [77.3025495654331, 35.133166329525906], [77.3025534223233, 35.13318110612511], [77.31665493999247, 35.62772158911965], [77.33110398154683, 36.12220894050683], [77.33105990105106, 36.12225121038974], [77.33102283135682, 36.12229765689839], [77.33100460322864, 36.12230084506779], [76.11148182295808, 36.13983073845944], [76.11142996868145, 36.13979463539234], [76.11137298204758, 36.13976402471305], [76.11137015041298, 36.13975304210107]]}, 'SOLAR_IRRADIANCE_B12': 85.25, 'SOLAR_IRRADIANCE_B10': 367.15, 'SOLAR_IRRADIANCE_B11': 245.59, 'GENERATION_TIME': 1533544120000, 'quality_check': 'PASSED', 'SOLAR_IRRADIANCE_B8A': 955.32, 'CLOUD_COVERAGE_ASSESSMENT': 17.82, 'system:time_end': 1533534429210, 'system:time_start': 1533534429210, 'DATASTRIP_ID': 'S2A_OPER_MSI_L1C_DS_EPAE_20180806T082840_S20180806T054709_N02.06', 'PROCESSING_BASELINE': '02.06', 'SENSING_ORBIT_NUMBER': 5, 'SENSING_ORBIT_DIRECTION': 'DESCENDING', 'GRANULE_ID': 'L1C_T43SFV_A016304_20180806T054709', 'REFLECTANCE_CONVERSION_CORRECTION': 0.971142780141, 'MEAN_INCIDENCE_AZIMUTH_ANGLE_B8': 222.563127344, 'DATATAKE_TYPE': 'INS-NOBS', 'MEAN_INCIDENCE_AZIMUTH_ANGLE_B9': 217.029219609, 'MEAN_INCIDENCE_AZIMUTH_ANGLE_B6': 218.749237812, 'MEAN_INCIDENCE_AZIMUTH_ANGLE_B7': 217.950995483, 'MEAN_INCIDENCE_AZIMUTH_ANGLE_B4': 219.590313425, 'MEAN_INCIDENCE_ZENITH_ANGLE_B1': 3.56122315316, 'MEAN_INCIDENCE_AZIMUTH_ANGLE_B5': 219.314619695, 'MEAN_INCIDENCE_AZIMUTH_ANGLE_B2': 224.016626867, 'MEAN_INCIDENCE_AZIMUTH_ANGLE_B3': 221.028706458, 'MEAN_INCIDENCE_ZENITH_ANGLE_B5': 3.24099803238, 'MEAN_INCIDENCE_AZIMUTH_ANGLE_B1': 217.284668877, 'MEAN_INCIDENCE_ZENITH_ANGLE_B4': 3.16756052897, 'MEAN_INCIDENCE_ZENITH_ANGLE_B3': 3.05068447569, 'MEAN_INCIDENCE_ZENITH_ANGLE_B2': 2.95220293506, 'MEAN_INCIDENCE_ZENITH_ANGLE_B9': 3.65100196172, 'MEAN_INCIDENCE_ZENITH_ANGLE_B8': 3.00025499287, 'MEAN_INCIDENCE_ZENITH_ANGLE_B7': 3.39045831864, 'MEAN_INCIDENCE_ZENITH_ANGLE_B6': 3.3161436516, 'MEAN_SOLAR_ZENITH_ANGLE': 24.5122884229, 'MEAN_INCIDENCE_ZENITH_ANGLE_B8A': 3.47018433867, 'MGRS_TILE': '43SFV', 'CLOUDY_PIXEL_PERCENTAGE': 17.82, 'PRODUCT_ID': 'S2A_MSIL1C_20180806T053641_N0206_R005_T43SFV_20180806T082840', 'MEAN_INCIDENCE_ZENITH_ANGLE_B10': 3.13105539604, 'SOLAR_IRRADIANCE_B9': 812.92, 'DEGRADED_MSI_DATA_PERCENTAGE': 0, 'MEAN_INCIDENCE_ZENITH_ANGLE_B11': 3.29830148981, 'MEAN_INCIDENCE_ZENITH_ANGLE_B12': 3.48365507793, 'SOLAR_IRRADIANCE_B6': 1287.61, 'MEAN_INCIDENCE_AZIMUTH_ANGLE_B10': 219.495192224, 'SOLAR_IRRADIANCE_B5': 1424.64, 'MEAN_INCIDENCE_AZIMUTH_ANGLE_B11': 217.91212122, 'SOLAR_IRRADIANCE_B8': 1041.63, 'MEAN_INCIDENCE_AZIMUTH_ANGLE_B12': 216.830536527, 'SOLAR_IRRADIANCE_B7': 1162.08, 'SOLAR_IRRADIANCE_B2': 1959.72, 'SOLAR_IRRADIANCE_B1': 1884.69, 'SOLAR_IRRADIANCE_B4': 1512.06, 'SOLAR_IRRADIANCE_B3': 1823.24, 'system:asset_size': 1485702114, 'system:index': '20180806T053641_20180806T054709_T43SFV'}}\n",
            "{'id': 'B2', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': 0, 'max': 65535}, 'dimensions': [10980, 10980], 'crs': 'EPSG:32643', 'crs_transform': [10, 0, 600000, 0, -10, 4000020]}\n",
            "[10980, 10980]\n",
            "{'type': 'Projection', 'crs': 'EPSG:32643', 'transform': [10, 0, 600000, 0, -10, 4000020]}\n",
            "[10, 0, 600000, 0, -10, 4000020]\n",
            "[76.11148057532596, 35.13300633161561, 77.30265790230024, 36.139740730510006] 76.11148057532596 36.139740730510006\n",
            "([76.11148057532596, 36.139740730510006], [76.11148057532596, 35.13300633161561], [77.30265790230024, 35.13300633161561], [77.30265790230024, 36.139740730510006])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pyproj/crs/crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
            "  return _prepare_from_string(\" \".join(pjargs))\n",
            "/usr/local/lib/python3.6/dist-packages/pyproj/crs/crs.py:294: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
            "  projstring = _prepare_from_string(\" \".join((projstring, projkwargs)))\n",
            "/usr/local/lib/python3.6/dist-packages/pyproj/crs/crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
            "  return _prepare_from_string(\" \".join(pjargs))\n",
            "/usr/local/lib/python3.6/dist-packages/pyproj/crs/crs.py:294: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
            "  projstring = _prepare_from_string(\" \".join((projstring, projkwargs)))\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: This function is deprecated. See: https://pyproj4.github.io/pyproj/stable/gotchas.html#upgrading-to-pyproj-2-from-pyproj-1\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: This function is deprecated. See: https://pyproj4.github.io/pyproj/stable/gotchas.html#upgrading-to-pyproj-2-from-pyproj-1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'state': 'READY', 'description': '20180806T053641_20180806T054709_T43SFV', 'creation_timestamp_ms': 1595397197959, 'update_timestamp_ms': 1595397197959, 'start_timestamp_ms': 0, 'task_type': 'EXPORT_IMAGE', 'id': 'G6NJDRO62TEV7PDGK4ANSV57', 'name': 'projects/earthengine-legacy/operations/G6NJDRO62TEV7PDGK4ANSV57'}\n",
            "[<Task EXPORT_IMAGE: 20180806T053641_20180806T054709_T43SFV (READY)>, <Task EXPORT_IMAGE: 20180806T053641_20180806T054709_T43SFV (COMPLETED)>, <Task EXPORT_IMAGE: 20190925T053639_20190925T054354_T43SFV (COMPLETED)>, <Task EXPORT_IMAGE: Landsat07image (COMPLETED)>, <Task EXPORT_IMAGE: Landsat07image (COMPLETED)>, <Task EXPORT_IMAGE: Landsat07image (COMPLETED)>, <Task EXPORT_IMAGE: Landsat07image (COMPLETED)>, <Task EXPORT_IMAGE: Landsat07image (COMPLETED)>, <Task EXPORT_IMAGE: Landsat07image (COMPLETED)>, <Task EXPORT_IMAGE: Landsat07image (COMPLETED)>, <Task EXPORT_IMAGE: Landsat07image (COMPLETED)>, <Task EXPORT_IMAGE: Landsat07image (COMPLETED)>, <Task EXPORT_IMAGE: Landsat07image (COMPLETED)>, <Task EXPORT_IMAGE: Landsat07image (COMPLETED)>, <Task EXPORT_IMAGE: Landsat07image (COMPLETED)>]\n",
            "Transferring Data to Drive..................\n",
            "Transferring Data to Drive..................\n",
            "Transferring Data to Drive..................\n",
            "Transferring Data to Drive..................\n",
            "Transferring Data to Drive..................\n",
            "Transferring Data to Drive..................\n",
            "Transferring Data to Drive..................\n",
            "Transferring Data to Drive..................\n",
            "Transferring Data to Drive..................\n",
            "Transferring Data to Drive..................\n",
            "Transferring Data to Drive..................\n",
            "Transferring Data to Drive..................\n",
            "Transferring Data to Drive..................\n",
            "Transferring Data to Drive..................\n",
            "Transferring Data to Drive..................\n",
            "Transferring Data to Drive..................\n",
            "Transferring Data to Drive..................\n",
            "Transferring Data to Drive..................\n",
            "Transferring Data to Drive..................\n",
            "Transferring Data to Drive..................\n",
            "Done with the Export to the Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qcicdTqcY2f",
        "colab_type": "text"
      },
      "source": [
        "This portion contains the network definition. At the moment I am taking GroupNorm equal to number of channels which should be equal to the instance Norm. There are four encoder and four decoder units. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJr39RUXbnMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ConvBnRelu(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):\n",
        "        super(ConvBnRelu, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride,padding_mode='replicate')\n",
        "        self.bn = nn.BatchNorm2d(in_channels)\n",
        "        #self.bn = nn.GroupNorm(in_channels,in_channels)\n",
        "        #self.relu = nn.ReLU()\n",
        "        self.relu = nn.LeakyReLU()\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = self.bn(x)\n",
        "        x = self.conv(x)       \n",
        "        x = self.relu(x)        \n",
        "        return x\n",
        "\n",
        "class StackEncoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(StackEncoder, self).__init__()\n",
        "        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=1)\n",
        "        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=1)\n",
        "        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convr1(x)\n",
        "        x = self.convr2(x)\n",
        "        x_trace = x\n",
        "        x = self.maxPool(x)\n",
        "        return x, x_trace\n",
        "\n",
        "class StackEncoder2(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(StackEncoder2, self).__init__()\n",
        "        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=1)\n",
        "        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=1)\n",
        "        self.convr3 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=1)\n",
        "        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convr1(x)\n",
        "        x = self.convr2(x)\n",
        "        x = self.convr3(x)\n",
        "       \n",
        "        x_trace = x\n",
        "        x = self.maxPool(x)\n",
        "        return x, x_trace\n",
        "\n",
        "class StackDecoder(nn.Module):\n",
        "    def __init__(self, in_channels1,in_channels2, out_channels):\n",
        "        super(StackDecoder, self).__init__()\n",
        "        self.upSample = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
        "        #self.upSample = nn.ConvTranspose2d(in_channels1,in_channels1, (2,2), stride=2)\n",
        "        self.convr1 = ConvBnRelu(in_channels1+in_channels2, out_channels, kernel_size=(3, 3), stride=1, padding=1)\n",
        "        # Crop + concat step between these 2\n",
        "        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=1)\n",
        "     \n",
        "    def _crop_concat(self, upsampled, bypass):\n",
        "        \"\"\"\n",
        "         Crop y to the (h, w) of x and concat them.\n",
        "         Used for the expansive path.\n",
        "        Returns:\n",
        "            The concatenated tensor\n",
        "        \"\"\"\n",
        "     #   c = (bypass.size()[2] - upsampled.size()[2]) // 2\n",
        "     #   bypass = F.pad(bypass, (-c, -c, -c, -c))\n",
        "\n",
        "        return torch.cat((upsampled, bypass), 1)\n",
        "\n",
        "    def forward(self, x, down_tensor):\n",
        "        x = self.upSample(x)\n",
        "        x = self._crop_concat(x, down_tensor)\n",
        "        x = self.convr1(x)    \n",
        "        x = self.convr2(x)\n",
        "        \n",
        "       # x = self.convr3(x)\n",
        "        return x\n",
        "\n",
        "class StackDecoder2(nn.Module):\n",
        "    def __init__(self, in_channels1,in_channels2, out_channels):\n",
        "        super(StackDecoder2, self).__init__()\n",
        "\n",
        "        self.upSample = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
        "        #self.upSample = nn.ConvTranspose2d(in_channels1,in_channels1, (2,2), stride=2)\n",
        "        self.convr1 = ConvBnRelu(in_channels1+in_channels2, out_channels, kernel_size=(3, 3), stride=1, padding=1)\n",
        "        # Crop + concat step between these 2\n",
        "        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=1)\n",
        "        self.convr3 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=1)\n",
        "     \n",
        "    def _crop_concat(self, upsampled, bypass):\n",
        "        \"\"\"\n",
        "         Crop y to the (h, w) of x and concat them.\n",
        "         Used for the expansive path.\n",
        "        Returns:\n",
        "            The concatenated tensor\n",
        "        \"\"\"\n",
        "     #   c = (bypass.size()[2] - upsampled.size()[2]) // 2\n",
        "     #   bypass = F.pad(bypass, (-c, -c, -c, -c))\n",
        "\n",
        "        return torch.cat((upsampled, bypass), 1)\n",
        "\n",
        "    def forward(self, x, down_tensor):\n",
        "        x = self.upSample(x)\n",
        "        x = self._crop_concat(x, down_tensor)\n",
        "        x = self.convr1(x)    \n",
        "        x = self.convr2(x)\n",
        "        x = self.convr3(x)\n",
        "       # x = self.convr3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class UNetOriginal(nn.Module):\n",
        "    @staticmethod\n",
        "    def weight_init(m):\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            torch.nn.init.kaiming_normal(m.weight.data)\n",
        "\n",
        "    def __init__(self, in_shape):\n",
        "        super(UNetOriginal, self).__init__()\n",
        "        channels, height, width = in_shape\n",
        "\n",
        "        self.down1 = StackEncoder(channels,16)\n",
        "        self.down2 = StackEncoder(16, 16)\n",
        "        self.down3 = StackEncoder2(16, 16)\n",
        "        self.down4 = StackEncoder2(16, 16)\n",
        "        self.down5 = StackEncoder2(16, 16)\n",
        "        self.center = nn.Sequential(\n",
        "            ConvBnRelu(16, 16, kernel_size=(3, 3), stride=1, padding=1),\n",
        "            ConvBnRelu(16, 16, kernel_size=(3, 3), stride=1, padding=1)\n",
        "        )\n",
        "\n",
        "        self.up1 = StackDecoder2(in_channels1=16,in_channels2=16, out_channels=16)\n",
        "        self.up2 = StackDecoder2(in_channels1=16,in_channels2=16, out_channels=16)\n",
        "        self.up3 = StackDecoder2(in_channels1=16,in_channels2=16, out_channels=16)\n",
        "        self.up4 = StackDecoder(in_channels1=16,in_channels2=16, out_channels=16)\n",
        "        self.up5 = StackDecoder(in_channels1=16,in_channels2=16, out_channels=16)\n",
        "        # 1x1 convolution at the last layer\n",
        "        # Different from the paper is the output size here\n",
        "        self.output_seg_map = nn.Conv2d(16, 2, kernel_size=(1, 1), padding=0, stride=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, x_trace1 = self.down1(x)  # Calls the forward() method of each layer\n",
        "        x, x_trace2 = self.down2(x)\n",
        "        x, x_trace3 = self.down3(x)\n",
        "        x, x_trace4 = self.down4(x)\n",
        "        x, x_trace5 = self.down5(x)\n",
        "\n",
        "        x = self.center(x)\n",
        "\n",
        "        x = self.up1(x, x_trace5)\n",
        "        x = self.up2(x, x_trace4)\n",
        "        x = self.up3(x, x_trace3)\n",
        "        x = self.up4(x, x_trace2)\n",
        "        x = self.up5(x, x_trace1)\n",
        "        \n",
        "        out = self.output_seg_map(x)\n",
        "        out = torch.squeeze(out, dim=1)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpA76Tucjd4Z",
        "colab_type": "text"
      },
      "source": [
        "The inference using the trained model is done here.  The \"UNet_Lakes\" contains the trained model. The input image is imported from the Google Drive. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93g7du4TEW2m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "669bdfe6-5455-45a0-a2d3-183bb68be08d"
      },
      "source": [
        "WINDOW_SIZE = (512,512) # Patch size\n",
        "WINDOW_SIZE = (512,512) # Patch size\n",
        "IN_CHANNELS = 13# Number of input channels (e.g. RGB)\n",
        "BATCH_SIZE = 8 # Number of samples in a mini-batch\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1/(1+np.exp(-z))\n",
        "def count_sliding_window(top, step=10, window_size=(20,20)):\n",
        "    \"\"\" Count the number of windows in an image \"\"\"\n",
        "    c = 0\n",
        "    for x in range(0, top.shape[0], step):\n",
        "        if x + window_size[0] > top.shape[0]:\n",
        "            x = top.shape[0] - window_size[0]\n",
        "        for y in range(0, top.shape[1], step):\n",
        "            if y + window_size[1] > top.shape[1]:\n",
        "                y = top.shape[1] - window_size[1]\n",
        "            c += 1\n",
        "    return c\n",
        "\n",
        "def grouper(n, iterable):\n",
        "    \"\"\" Browse an iterator by chunk of n elements \"\"\"\n",
        "    it = iter(iterable)\n",
        "    while True:\n",
        "        chunk = tuple(itertools.islice(it, n))\n",
        "        if not chunk:\n",
        "            return\n",
        "        yield chunk\n",
        "\n",
        "def sliding_window(top, step=10, window_size=(20,20)):\n",
        "    \"\"\" Slide a window_shape window across the image with a stride of step \"\"\"\n",
        "    for x in range(0, top.shape[0], step):\n",
        "        if x + window_size[0] > top.shape[0]:\n",
        "            x = top.shape[0] - window_size[0]\n",
        "        for y in range(0, top.shape[1], step):\n",
        "            if y + window_size[1] > top.shape[1]:\n",
        "                y = top.shape[1] - window_size[1]\n",
        "            yield x, y, window_size[0], window_size[1]\n",
        "\n",
        "\n",
        "def get_random_pos(img, window_shape):\n",
        "    \"\"\" Extract of 2D random patch of shape window_shape in the image \"\"\"\n",
        "    w, h = window_shape\n",
        "    W, H = img.shape[-2:]\n",
        "    x1 = random.randint(0, W - w - 1)\n",
        "    x2 = x1 + w\n",
        "    y1 = random.randint(0, H - h - 1)\n",
        "    y2 = y1 + h\n",
        "    return x1, x2, y1, y2\n",
        " \n",
        "def sliding_window_N(top, step=10, window_size=(20,20)):\n",
        "    \"\"\" Slide a window_shape window across the image with a stride of step \"\"\"\n",
        "    coord=[]    \n",
        "    for x in range(0, top.shape[0], step):\n",
        "        if x + window_size[0] > top.shape[0]:\n",
        "            x = top.shape[0] - window_size[0]\n",
        "        for y in range(0, top.shape[1], step):\n",
        "            if y + window_size[1] > top.shape[1]:\n",
        "                y = top.shape[1] - window_size[1]\n",
        "            coord.append((x,y))            \n",
        "    return coord\n",
        "\n",
        "def testOnly(net, test_ids, all=False, stride=WINDOW_SIZE[0], batch_size=BATCH_SIZE, window_size=WINDOW_SIZE):\n",
        "    #test_files  = glob(test_Folder)\n",
        "    test_ids = list(range(1,len(test_files)+1))\n",
        "    for k in range(len(test_ids)):\n",
        "        #test_images = (1 / 255 * np.asarray(io.imread(test_files[int(test_ids[k])-1]), dtype='float32') )\n",
        "        #test_images = (1 / 500) * np.asarray(io.imread(testFile), dtype='float32') \n",
        "        print(test_files[int(test_ids[k])-1])\n",
        "        with rio.open(test_files[int(test_ids[k])-1]) as img :\n",
        "          test_images= img.read()\n",
        "          \n",
        "        test_images = np.log(test_images+1)\n",
        "        test_images = test_images/500\n",
        "        test_images = test_images/3.5\n",
        "        test_images[test_images>1]=1\n",
        "        all_preds = []\n",
        "        net.eval()\n",
        "  \n",
        "        img=test_images\n",
        "        pred = np.zeros((img.shape[0],img.shape[1],N_CLASSES),)\n",
        "        gt = np.zeros((img.shape[0],img.shape[1]))\n",
        "        stride=256\n",
        "        total = count_sliding_window(gt, step=stride, window_size=window_size) // batch_size\n",
        "        for i, coords in enumerate(tqdm(grouper(batch_size, sliding_window(gt, step=stride, window_size=window_size)), total=total, leave=False)):\n",
        "            # Display in progress results\n",
        "                    \n",
        "            # Build the tensor\n",
        "            image_patches = [np.copy(img[x:x+w, y:y+h]).transpose((2,0,1)) for x,y,w,h in coords]\n",
        "            image_patches = np.asarray(image_patches)\n",
        "            image_patches = Variable(torch.from_numpy(image_patches).cuda(), volatile=True)\n",
        "            \n",
        "            # Do the inference\n",
        "            outs = net(image_patches)\n",
        "            outs = F.softmax(outs, dim=1)\n",
        "            outs = outs.data.cpu().numpy()\n",
        "            \n",
        "            # Fill in the results array\n",
        "            for out, (x, y, w, h) in zip(outs, coords):\n",
        "                out = out.transpose((1,2,0))\n",
        "                pred[x:x+w, y:y+h] += out\n",
        "            del(outs)\n",
        "\n",
        "        pred = np.argmax(pred, axis=-1)\n",
        "        \n",
        "        fig = plt.figure()\n",
        "        fig.add_subplot(1,2,1)\n",
        "        plt.imshow(np.asarray(255 * img[:,:,1], dtype='uint8'))\n",
        "        fig.add_subplot(1,2,2)\n",
        "        plt.imshow((pred))\n",
        "        plt.show()\n",
        "        return pred\n",
        "\n",
        "LABELS = [\"Backgr\",\"Lakes\"] \n",
        "mylabels = np.array(LABELS)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# instantiate the network     \n",
        "net = UNetOriginal((IN_CHANNELS,WINDOW_SIZE[0],WINDOW_SIZE[1]))      \n",
        "net=net.cuda() \n",
        "path = F\"/content/gdrive/My Drive/Nauman_Lakes_96_0948_0890\"\n",
        "net.load_state_dict(torch.load(path))\n",
        "#net = train(net, train_loader, val_loader, test_loader, optimizer,200, scheduler)\n",
        "test_files  = glob(r'/content/gdrive/My Drive/20180806T053641_20180806T054709_T43SFV.tif')\n",
        "print(test_files)\n",
        "test_ids=[1]\n",
        "pred = testOnly(net, test_ids, all=False, stride=min(WINDOW_SIZE))\n",
        "#acc = test(net, testOnly_ids, IMAGE_FOLDER_Test, BATCH_SIZE, WINDOW_SIZE, len(LABELS)) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/gdrive/My Drive/20180806T053641_20180806T054709_T43SFV.tif']\n",
            "/content/gdrive/My Drive/20180806T053641_20180806T054709_T43SFV.tif\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MADSir_SjOII",
        "colab_type": "text"
      },
      "source": [
        "The predicted image along with the false color image is displayed over the openstreet map base layer using Folium library. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3Fo67HZ_l5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EE_TILES = 'https://earthengine.googleapis.com/map/{mapid}/{{z}}/{{x}}/{{y}}?token={token}'\n",
        "bands=['B1','B2','B3','B4','B5','B6','B7','B8','B9']\n",
        "bounds1 = [[lat1,lon1],[lat2, lon2]]\n",
        "m=folium.Map(location=[ lat1,lon1],zoom_start=12)\n",
        "mapid=image.getMapId({'bands':['B5','B4','B3']})    \n",
        "folium.TileLayer(\n",
        "  tiles=EE_TILES.format(**mapid),\n",
        "  attr='Google Earth Engine',\n",
        "  overlay=True,\n",
        " ).add_to(m)  \n",
        "#m.add_child(folium.LayerControl())\n",
        "\n",
        "\n",
        "img = folium.raster_layers.ImageOverlay(\n",
        "  name='PredictedImage',\n",
        "  image=pred,\n",
        "  bounds=bounds1,\n",
        "  interactive=True,\n",
        "  overlay=True,\n",
        ")\n",
        "img.add_to(m)\n",
        "m.add_child(folium.LayerControl())\n",
        "m"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}